# UMA_IE500_Data_Mining

# Predictive Modeling Pipeline for Structured Datasets

This project presents a complete data science pipeline for building and evaluating machine learning models using structured datasets. The pipeline includes data cleaning, exploratory data analysis and visualization, feature engineering, model training (using multiple algorithms), and comprehensive model selection and evaluation.

## ğŸ“ Project Structure
(Important notebooks to see and run to get the dataset, or the model states #if not having the zip file containing everything)

```
[0] Data_Cleaning_Test
|   â””â”€â”€ cleaning_trial.ipynb
[1] Data Exploration and Visualization
â”‚   â””â”€â”€ explore_and_vis_time.ipynb
[2] Feature Engineering_Test
â”‚   â””â”€â”€ Feature_selection_trial.ipynb
[3] [3] Full preparation_engineering and baseline model evaluation
â”‚   â”œâ”€â”€ distribution check.ipynb
â”‚   â”œâ”€â”€ full dataset preparation and baseline model evaluation.ipynb
â”‚   â””â”€â”€ shuffle closed model experiment notebook.ipynb
[4] Model Training
â”‚   â”œâ”€â”€ XGBoost.ipynb
â”‚   â”œâ”€â”€ decision_tree.ipynb
â”‚   â”œâ”€â”€ knn.ipynb
|   â”œâ”€â”€ logiic_regression.ipynb
â”‚   â””â”€â”€ random_forest.ipynb
[5] Model Selection
â”‚   â”œâ”€â”€ Model_eval_and_compare.ipynb
â”‚   â”œâ”€â”€ check_for_ensemble_model.ipynb
â”‚   â””â”€â”€ Chosen_model_RF_vis_and_interpretation

Additional Files:
- .gitignore
- README.md
- _getting_the_data.py
- data_scaling.py
- feature_engineering_function.py
```

## ğŸ§  Model Overview

We explore and compare the performance of multiple machine learning models:

- Decision Tree
- Random Forest
- K-Nearest Neighbors (KNN)
- XGBoost
- logistic regression

Evaluation metrics include accuracy, precision, recall, F1-score, and ROC-AUC where applicable (e.g. not for KNN).
Furthermore, for final evaluation of candidate models - RF and XGB - further qualitative evaluation was conduncted. For details see the notebook: "Model_eval_and_compare"

## ğŸ”§ Technologies Used

- Python (Jupyter Notebooks)
- Pandas, NumPy
- Scikit-learn
- XGBoost
- Matplotlib, Seaborn (for visualization)
etc.

## ğŸ§‘â€ğŸ¤â€ğŸ§‘ Contributors

- **Chengyi Hua**, 2117289, [chengyi.hua@students.uni-mannheim.de](mailto:chengyi.hua@students.uni-mannheim.de)  
- **Shamalan Rajesvaran**, 2115475, [shamalan.rajesvaran@students.uni-mannheim.de](mailto:shamalan.rajesvaran@students.uni-mannheim.de)  
- **Bahri SelÃ§uk EÅŸkil**, 2117150, [bahri.eskil@students.uni-mannheim.de](mailto:bahri.eskil@students.uni-mannheim.de)  
- **Nicolas Balzek**, 1709460, [nicolas.balzek@students.uni-mannheim.de](mailto:nicolas.balzek@students.uni-mannheim.de)  
- **Bofan Chen**, 2190412, [bofan.chen@students.uni-mannheim.de](mailto:bofan.chen@students.uni-mannheim.de)

## ğŸ—“ï¸ Last Updated

15.05.2025


